{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to maintain strategy for competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date: 28/02/2017\n",
    "\n",
    "* Simple GRU network with pretrained vectors for initialization\n",
    "    * Preprocessing - removing stop words, punctuations and /n\n",
    "    * Pretrained embeddings  - Glove 42B300d; FasText 2M300d; Word2vec gensim trained on current corpus\n",
    "    * Network architectures \n",
    "        * Bidirectional\n",
    "        * MaxPool, AvgPool and AttentionPool (individual and all together)\n",
    "    * Optimizers - Adam and RMSprop\n",
    "    * Hyperparameters tuning with Hyperopt\n",
    "    \n",
    "* LSTM-GRNN (tang et. al) - Encode words followed by sentence\n",
    "    * http://aclweb.org/anthology/D15-1167\n",
    "    * Avg, Max, Attention\n",
    "\n",
    "* Hierarchical Attention Networks for Document Classification\n",
    "    * http://aclweb.org/anthology/N/N16/N16-1174.pdf\n",
    "        \n",
    "* Sub-word embeddings for OOV words\n",
    "\n",
    "* Char RNN with learned embeddings as target to encode OOV words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Strategy\n",
    "Stratified 10-fold "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final stretch\n",
    "\n",
    "- Create Reddit embeddings ( 1 day)\n",
    "    - run best models with reddit embeddings \n",
    "        - MK GRU (~ 3 hours)\n",
    "        - Sohm Capsule (~ 3 hours)\n",
    "        - Soham GRU (~ 3 hours)\n",
    "- Run Embedding based Spell corrector + BPE breaking and run best models (run time 3 hours MK; 6 hours Sohm)\n",
    "\n",
    "- Language translation - 4 hours\n",
    "\n",
    "- Skip middle portion -- create new corpus\n",
    "\n",
    "- Gensim Sent2vec - 6 hours\n",
    "\n",
    "- char ngrams on toxic corpus + Add with word embeddings  - 6 hours\n",
    "    - run best models\n",
    "    \n",
    "- Improve linear models - 12-24 hours\n",
    "    - nb-svm\n",
    "    \n",
    "- Lightgbm on concate layer of best model - 6 hours\n",
    "\n",
    "- Hierarchical Ntework  - 24 hours\n",
    "    - GRU sent\n",
    "    - Char n-grams CNN\n",
    "    - Tune and run with fasttext and reddit embeddings\n",
    "\n",
    "- Add Quote, 1st Cap word and All word vectors to word embedding - 8 hours\n",
    "\n",
    "\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan:\n",
    "\n",
    "* Language translation\n",
    "* Create preprocessed X_train, X_test and embedding matrix\n",
    "    - Embeddings - {Glove, reddit, fastext, word2vec on corrent corpus}\n",
    "    + Preprocessing {remove all syms, keep certain sysm}\n",
    "    + Corrections {no_correction, BPE splits, spell_correct+BPE}\n",
    "    \n",
    "    Total 4 x 2 x 3 = 24 sets (Select 8 sets )\n",
    "\n",
    "* Pick 3 best models \n",
    "    - Run through all sets (8 * 3 = 24 hours running time)\n",
    "    \n",
    "* Word embedding + Char n-gram BPE/word2vec\n",
    "    - Select 3 models (3 x 3 + 6 hours developement = 15 hours)\n",
    "\n",
    "* Hierachical with best settings \n",
    "    - models with best settings 5-6\n",
    "    \n",
    "* Lightgbm on concat layer and tuning - \n",
    "    - 24 hours of work\n",
    "    - if initial results not good, then autoencoder on complete sent embedding concatenated and then take compressed layer\n",
    "    \n",
    "* Gensim sent2vec train and tune\n",
    "    - 24 hours of work \n",
    "    \n",
    "    \n",
    "* Hierarchical with First letter caps + FUll caps + POS tags vectors in addition to embeddings (if time permits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
