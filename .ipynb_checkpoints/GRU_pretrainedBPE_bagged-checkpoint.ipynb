{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple GRU network with pretrained vectors for initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohsin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys, os, re, csv, codecs, gc, numpy as np, pandas as pd\n",
    "import tensorflow as tf\n",
    "#from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, Permute, GRU, Conv1D, LSTM, Embedding, Dropout, Activation, CuDNNLSTM, CuDNNGRU, concatenate, Flatten\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalAveragePooling1D, BatchNormalization, SpatialDropout1D, Dot\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "import keras.backend as K\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from functools import reduce\n",
    "from keras.layers import Layer, PReLU, SpatialDropout1D\n",
    "from keras import initializers\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize, TweetTokenizer, MWETokenizer, ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "np.random.seed(786)\n",
    "\n",
    "from Tokenizer import Tokenizer\n",
    "from ZeroMaskedLayer import ZeroMaskedLayer\n",
    "from AttentionLayer import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../input/'\n",
    "utility_path = '../utility/'\n",
    "comp = 'jigsaw-toxic-comment-classification-challenge/'\n",
    "EMBEDDING_FILE=f'{utility_path}glove.42B.300d.txt'\n",
    "TRAIN_DATA_FILE=f'{path}train.csv'\n",
    "TEST_DATA_FILE=f'{path}test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'wo', \"n't\", 'do', 'this', 'check', '!', '!', '!']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"I won't do this check!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(series):\n",
    "    return series.apply(lambda s: unicodedata.normalize('NFKC', str(s)))\n",
    "\n",
    "\n",
    "def multiple_replace(text, adict):\n",
    "    rx = re.compile('|'.join(map(re.escape, adict)))\n",
    "\n",
    "    def one_xlat(match):\n",
    "        return adict[match.group(0)]\n",
    "\n",
    "    return rx.sub(one_xlat, text)\n",
    "\n",
    "STOP_WORDS = set(stopwords.words( 'english' ))\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(series):\n",
    "    series = unicodeToAscii(series)\n",
    "    series = series.str.lower()\n",
    "    series = series.str.replace(r\"(\\n){1,}\", \" \")\n",
    "    #series = series.str.replace(r\"\\'\", \"\")\n",
    "    series = series.str.replace(r\"\\-\", \"\")\n",
    "    series = series.str.replace(r\"[^0-9a-zA-Z.,!?\\\"':]+\", \" \")\n",
    "    series = series.str.replace(\"([a-z0-9]{2,}\\.){2,}[a-z]{2,}\", \"url\") \n",
    "    #Replace URL's by url\n",
    "    series = series.str.replace(\"\\d\", \"0\")\n",
    "    \n",
    "\n",
    "    return series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8) (153164, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(TRAIN_DATA_FILE)\n",
    "test = pd.read_csv(TEST_DATA_FILE)\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[list_classes].values\n",
    "\n",
    "#Get validation folds\n",
    "train['target_str'] = reduce(lambda x,y: x+y, [train[col].astype(str) for col in list_classes])\n",
    "train['target_str'] = train['target_str'].replace('110101', '000000').replace('110110','000000')\n",
    "cvlist1 = list(StratifiedKFold(n_splits=10, random_state=786).split(train, train['target_str'].astype('category')))\n",
    "cvlist2 = list(StratifiedShuffleSplit(n_splits=5, test_size=0.05, random_state=786).split(train, train['target_str'].astype('category')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in train, test:\n",
    "    df[\"comment_text\"] = normalizeString(df[\"comment_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' delete request someone hacked my account. i have fixed it now, but please delete this page: george walker faggot '"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.comment_text.sample(1).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.concat([train[\"comment_text\"].astype(str), test[\"comment_text\"].astype(str)]).reset_index(drop=True)[:len(train), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 150) (153164, 150)\n"
     ]
    }
   ],
   "source": [
    "MAX_FEATURES = 80000\n",
    "MAX_LEN = 150\n",
    "\n",
    "tok = Tokenizer(max_features=MAX_FEATURES, max_len=MAX_LEN, tokenizer=word_tokenize)\n",
    "X = tok.fit_transform(pd.concat([train[\"comment_text\"].astype(str), test[\"comment_text\"].astype(str)]))\n",
    "X_train = X[:len(train), :]\n",
    "X_test = X[len(train):, :]\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dick.sum']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"dick.sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('realible', 3),\n",
       " ('tyrannosaurs', 3),\n",
       " ('wikitalk', 3),\n",
       " ('jaron', 3),\n",
       " ('hokku', 3),\n",
       " ('bogdangiusca', 3),\n",
       " ('lmaz', 3),\n",
       " ('kwekwe', 3),\n",
       " ('dupri', 3),\n",
       " ('mistakened', 3),\n",
       " ('stitching', 3),\n",
       " ('nonmalicious', 3),\n",
       " ('abruptness', 3),\n",
       " ('riefenstahl', 3),\n",
       " ('sapience', 3),\n",
       " (\"hawai'i\", 3),\n",
       " ('dispelled', 3),\n",
       " ('tekhelet', 3),\n",
       " ('kanai', 3),\n",
       " ('questionmarks', 3),\n",
       " ('ugadawgs', 3),\n",
       " ('angiotensin', 3),\n",
       " ('perlis', 3),\n",
       " ('groaning', 3),\n",
       " ('floozie', 3),\n",
       " ('squealed', 3),\n",
       " ('crackwhore', 3),\n",
       " ('spurted', 3),\n",
       " ('deflagration', 3),\n",
       " ('neusner', 3),\n",
       " ('fattie', 3),\n",
       " ('decal', 3),\n",
       " ('hfcs', 3),\n",
       " ('captialization', 3),\n",
       " ('bethe', 3),\n",
       " ('psychoenergetic', 3),\n",
       " ('trott', 3),\n",
       " ('antibias', 3),\n",
       " ('neutralist', 3),\n",
       " ('livius.org', 3),\n",
       " ('lendering', 3),\n",
       " ('reawakening', 3),\n",
       " ('kajol', 3),\n",
       " ('britishenglish', 3),\n",
       " ('valedictorian', 3),\n",
       " ('disqualifications', 3),\n",
       " ('nsuboy', 3),\n",
       " ('asist', 3),\n",
       " ('juvenal', 3),\n",
       " ('escapade', 3),\n",
       " ('intdablink', 3),\n",
       " ('leadership.aspx', 3),\n",
       " ('effete', 3),\n",
       " ('roars', 3),\n",
       " ('wotc', 3),\n",
       " ('howicus', 3),\n",
       " ('nonissues', 3),\n",
       " ('fallacy.', 3),\n",
       " ('insee', 3),\n",
       " ('conurbations', 3),\n",
       " ('weaved', 3),\n",
       " ('pearen', 3),\n",
       " ('gratefull', 3),\n",
       " ('serach', 3),\n",
       " ('direclty', 3),\n",
       " ('mainspacetab', 3),\n",
       " ('pagetab', 3),\n",
       " ('earliesttab', 3),\n",
       " ('pagestab', 3),\n",
       " ('alfadog', 3),\n",
       " ('bullshido.net', 3),\n",
       " ('oneparty', 3),\n",
       " ('wike', 3),\n",
       " ('vandalazing', 3),\n",
       " ('gimmebot', 3),\n",
       " ('fiendly', 3),\n",
       " ('selffulfillment', 3),\n",
       " ('worldimprover.net', 3),\n",
       " ('absorbers', 3),\n",
       " ('tghe', 3),\n",
       " ('biger', 3),\n",
       " ('personalise', 3),\n",
       " (\"'emergency\", 3),\n",
       " ('rickles', 3),\n",
       " ('circuitous', 3),\n",
       " ('vignettes', 3),\n",
       " ('bellowed', 3),\n",
       " ('haftar', 3),\n",
       " ('salamanders', 3),\n",
       " ('immobile', 3),\n",
       " ('carbonates', 3),\n",
       " ('botlike', 3),\n",
       " ('playgirl', 3),\n",
       " ('digga', 3),\n",
       " ('istanbulensis', 3),\n",
       " ('ettore', 3),\n",
       " ('termer', 3),\n",
       " ('apprenticed', 3),\n",
       " ('bitforbit', 3),\n",
       " ('reichs', 3)]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.doc_freq.most_common(80000)[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "sp = spm.SentencePieceProcessor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.Load(\"../utility/en.wiki.bpe.op200000.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>657.000000</td>\n",
       "      <td>657.0</td>\n",
       "      <td>657.000000</td>\n",
       "      <td>657.000000</td>\n",
       "      <td>657.000000</td>\n",
       "      <td>657.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.079148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.003044</td>\n",
       "      <td>0.039574</td>\n",
       "      <td>0.004566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            toxic  severe_toxic     obscene      threat      insult  \\\n",
       "count  657.000000         657.0  657.000000  657.000000  657.000000   \n",
       "mean     0.079148           0.0    0.041096    0.003044    0.039574   \n",
       "\n",
       "       identity_hate  \n",
       "count     657.000000  \n",
       "mean        0.004566  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train.comment_text.str.contains(\"room.\"), list_classes].agg(['count', 'mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁bitches', '.', 'fuck']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.EncodeAsPieces(\"bitches.fuck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187990"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(\"../utility/en.wiki.bpe.op200000.d300.w2v.txt\"))\n",
    "len(embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 150) (153164, 150)\n"
     ]
    }
   ],
   "source": [
    "#embeddings_index\n",
    "tok = Tokenizer(max_features=MAX_FEATURES, max_len=MAX_LEN, tokenizer=sp.EncodeAsPieces)\n",
    "X = tok.fit_transform(pd.concat([train[\"comment_text\"].astype(str), test[\"comment_text\"].astype(str)]))\n",
    "X_train = X[:len(train), :]\n",
    "X_test = X[len(train):, :]\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_SIZE = 300\n",
    "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "oov_list =[]\n",
    "def initialize_embeddings(filename, embeddings_index, tokenizer):\n",
    "    #embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(filename))\n",
    "\n",
    "    word_index = tokenizer.vocab_idx\n",
    "    nb_words = min(MAX_FEATURES+1, len(word_index)+1)\n",
    "    embedding_matrix = np.zeros((nb_words, EMBED_SIZE))\n",
    "    for word, i in word_index.items():\n",
    "        if i > MAX_FEATURES: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            \n",
    "            #broken_words = sp.EncodeAsPieces(word)\n",
    "            #broken_words()\n",
    "            oov_list.append(word)\n",
    "    return (embedding_matrix, oov_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('olest', 3),\n",
       " ('▁flin', 3),\n",
       " ('▁tarski', 3),\n",
       " ('▁maiko', 3),\n",
       " ('▁sandanski', 3),\n",
       " ('▁combust', 3),\n",
       " ('▁malaga', 3),\n",
       " ('▁tapeworm', 3),\n",
       " ('▁borax', 3),\n",
       " ('▁phoen', 3),\n",
       " ('▁ival', 3),\n",
       " ('▁disob', 3),\n",
       " ('▁insideout', 3),\n",
       " ('▁heiden', 3),\n",
       " ('▁zaytsev', 3),\n",
       " ('▁deodor', 3),\n",
       " ('▁mechanization', 3),\n",
       " ('rca', 3),\n",
       " ('jill', 3),\n",
       " ('▁dissolves', 3),\n",
       " ('▁urbino', 3),\n",
       " ('tener', 3),\n",
       " ('▁sanaag', 3),\n",
       " ('urta', 3),\n",
       " ('▁dara', 3),\n",
       " ('meena', 3),\n",
       " ('▁polla', 3),\n",
       " ('▁iupui', 3),\n",
       " ('tto', 3),\n",
       " ('▁cleaving', 3),\n",
       " ('▁maye', 3),\n",
       " ('▁mussels', 3),\n",
       " ('▁delicacies', 3),\n",
       " ('eniya', 3),\n",
       " ('▁schreiber', 3),\n",
       " ('▁fitzgibbon', 3),\n",
       " ('udong', 3),\n",
       " ('▁pue', 3),\n",
       " ('▁subvers', 3),\n",
       " ('leva', 3),\n",
       " ('▁metastable', 3),\n",
       " ('▁phonograph', 3),\n",
       " ('shul', 3),\n",
       " ('sbee', 3),\n",
       " ('▁wendland', 3),\n",
       " ('▁gher', 3),\n",
       " ('equipment', 3),\n",
       " ('venomous', 3),\n",
       " ('ribo', 3),\n",
       " ('▁pessoa', 3),\n",
       " ('nicas', 3),\n",
       " ('inid', 3),\n",
       " ('▁woodward', 3),\n",
       " ('▁polyglot', 3),\n",
       " ('▁surjective', 3),\n",
       " ('▁typifies', 3),\n",
       " ('ghz', 3),\n",
       " ('▁unleashes', 3),\n",
       " ('▁diamondback', 3),\n",
       " ('▁logue', 3),\n",
       " ('▁xir', 3),\n",
       " ('▁kied', 3),\n",
       " ('▁zami', 3),\n",
       " ('▁mersenne', 3),\n",
       " ('ivna', 3),\n",
       " ('▁radim', 3),\n",
       " ('▁fatra', 3),\n",
       " ('▁toothpick', 3),\n",
       " ('▁conchita', 3),\n",
       " ('hunger', 3),\n",
       " ('▁ramzy', 3),\n",
       " ('▁steamroller', 3),\n",
       " ('▁corvallis', 3),\n",
       " ('branching', 3),\n",
       " ('juris', 3),\n",
       " ('tinted', 3),\n",
       " ('▁nucleic', 3),\n",
       " ('▁azadi', 3),\n",
       " ('▁alim', 3),\n",
       " ('▁kadam', 3),\n",
       " ('▁messines', 3),\n",
       " ('beek', 3),\n",
       " ('▁machinegun', 3),\n",
       " ('hirt', 3),\n",
       " ('▁kise', 3),\n",
       " ('faw', 3),\n",
       " ('▁afrikaners', 3),\n",
       " ('▁pilt', 3),\n",
       " ('▁schweizer', 3),\n",
       " ('▁stah', 3),\n",
       " ('▁lidd', 3),\n",
       " ('▁cala', 3),\n",
       " ('▁osasuna', 3),\n",
       " ('▁rapporteur', 3),\n",
       " ('▁rato', 3),\n",
       " ('incorrectly', 3),\n",
       " ('▁hany', 3),\n",
       " ('▁pernambuco', 3),\n",
       " ('instruction', 3),\n",
       " ('portionment', 3)]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.doc_freq.most_common(83000)[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80001, 300)\n",
      "0.0004608204601803373 0.28929758471650163\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix, oov_list = initialize_embeddings(EMBEDDING_FILE, embeddings_index, tok)\n",
    "print(embedding_matrix.shape)\n",
    "print(np.mean(embedding_matrix), np.std(embedding_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['▁jizz',\n",
       " '▁reall',\n",
       " 'utzer',\n",
       " 'cile',\n",
       " 'copyr',\n",
       " '▁advertis',\n",
       " 'incha',\n",
       " '▁cockro',\n",
       " 'acuse',\n",
       " 'amatory',\n",
       " 'onsored',\n",
       " '▁inadvert',\n",
       " '▁clich',\n",
       " 'ecially',\n",
       " '▁pagen',\n",
       " '▁attem',\n",
       " '▁answ',\n",
       " 'ungeons',\n",
       " 'rotum',\n",
       " '▁encycl',\n",
       " 'trypt',\n",
       " '▁behav',\n",
       " '▁deleter',\n",
       " '▁antide',\n",
       " '▁excer',\n",
       " 'reputable',\n",
       " '▁makedon',\n",
       " 'irected',\n",
       " '▁embarr',\n",
       " '▁mahaw',\n",
       " '▁undoub',\n",
       " 'olnick',\n",
       " '▁acknow',\n",
       " 'schnitt',\n",
       " '▁eshte',\n",
       " '▁poved',\n",
       " '▁irond',\n",
       " '▁copyr',\n",
       " '▁metaw',\n",
       " 'atever',\n",
       " '▁toky',\n",
       " '▁criter',\n",
       " 'leves',\n",
       " '▁scientif',\n",
       " '▁appre',\n",
       " 'ecock',\n",
       " '▁welcom',\n",
       " '▁proport',\n",
       " '▁confir',\n",
       " '▁inconsist',\n",
       " '▁pejor',\n",
       " 'urday',\n",
       " 'ypedia',\n",
       " 'oburg',\n",
       " 'eday',\n",
       " 'illaz',\n",
       " 'mosin',\n",
       " '▁einst',\n",
       " 'itorul',\n",
       " 'piff',\n",
       " '▁schnitz',\n",
       " 'viously',\n",
       " '▁tomor',\n",
       " '▁zapat',\n",
       " '▁sevend',\n",
       " 'ruction',\n",
       " '▁recip',\n",
       " '▁eaba',\n",
       " 'ignatus',\n",
       " '▁refere',\n",
       " '▁achiev',\n",
       " '▁suce',\n",
       " '▁compre',\n",
       " 'tirol',\n",
       " 'namese',\n",
       " '▁resemb',\n",
       " 'ailando',\n",
       " '▁yusufali',\n",
       " '▁qiw',\n",
       " 'icance',\n",
       " 'otre',\n",
       " '▁errone',\n",
       " '▁outrig',\n",
       " '▁disg',\n",
       " '▁nongo',\n",
       " 'amilton',\n",
       " 'arettes',\n",
       " 'adays',\n",
       " 'letely',\n",
       " '▁priyadar',\n",
       " 'ankings',\n",
       " 'isex',\n",
       " 'lourious',\n",
       " 'eens',\n",
       " '▁thous',\n",
       " 'enship',\n",
       " '▁adequ',\n",
       " '▁coinc',\n",
       " '▁nazil',\n",
       " '▁interpre',\n",
       " '▁opposit',\n",
       " 'casm',\n",
       " '▁emph',\n",
       " 'akukan',\n",
       " '▁paralymp',\n",
       " '▁disagre',\n",
       " 'ismith',\n",
       " '▁unwield',\n",
       " 'nieper',\n",
       " 'nedi',\n",
       " 'gbt',\n",
       " '▁inev',\n",
       " 'nalb',\n",
       " 'teenth',\n",
       " '▁nyer',\n",
       " '▁ethiop',\n",
       " 'anly',\n",
       " '▁joaqu',\n",
       " 'ulec',\n",
       " '▁inaug',\n",
       " '▁karata',\n",
       " 'encyclop',\n",
       " 'bbels',\n",
       " '▁injust',\n",
       " '▁bucure',\n",
       " '▁asym',\n",
       " 'vora',\n",
       " 'ambiguation',\n",
       " '▁pursu',\n",
       " '▁replac',\n",
       " '▁chicag',\n",
       " '▁emblaz',\n",
       " 'artment',\n",
       " 'werty',\n",
       " 'ieval',\n",
       " '▁liit',\n",
       " '▁subtit',\n",
       " '▁carthag',\n",
       " '▁dzier',\n",
       " '▁deserv',\n",
       " 'uguese',\n",
       " 'skoga',\n",
       " '▁coraz',\n",
       " 'onsei',\n",
       " '▁nefto',\n",
       " '▁guzm',\n",
       " '▁contex',\n",
       " '▁predomin',\n",
       " '▁emplo',\n",
       " 'grins',\n",
       " 'glot',\n",
       " '▁ingred',\n",
       " 'jeti',\n",
       " 'blech',\n",
       " 'bood',\n",
       " 'aysay',\n",
       " '▁gwill',\n",
       " '▁lesz',\n",
       " '▁aleg',\n",
       " 'ksang',\n",
       " 'kiem',\n",
       " '▁umri',\n",
       " 'ptember',\n",
       " 'urlionis',\n",
       " '▁maracan',\n",
       " 'scray',\n",
       " 'orities',\n",
       " 'dowell',\n",
       " '▁elfs',\n",
       " '▁challeng',\n",
       " '▁resear',\n",
       " 'bnb',\n",
       " 'eminun',\n",
       " '▁kapamp',\n",
       " 'beir',\n",
       " '▁disgu',\n",
       " '▁kitche',\n",
       " '▁absur',\n",
       " 'sored',\n",
       " 'yscrap',\n",
       " '▁jesen',\n",
       " 'furl',\n",
       " '▁postmed',\n",
       " 'isition',\n",
       " 'lating',\n",
       " '▁gjirokast',\n",
       " '▁snipp',\n",
       " '▁antipsych',\n",
       " 'undrum',\n",
       " 'riptive',\n",
       " '▁eble',\n",
       " 'erepublic',\n",
       " 'oslovak',\n",
       " 'raeg',\n",
       " '▁cienc',\n",
       " '▁writh',\n",
       " 'igies',\n",
       " '▁zamia',\n",
       " '▁istv',\n",
       " '▁albur',\n",
       " '▁inchi',\n",
       " '▁uniqu',\n",
       " 'autop',\n",
       " 'chihu',\n",
       " '▁ceau',\n",
       " '▁perenn',\n",
       " 'geant',\n",
       " 'jki',\n",
       " '▁comunic',\n",
       " '▁fawk',\n",
       " 'iesc',\n",
       " '▁brate',\n",
       " '▁sebest',\n",
       " '▁napred',\n",
       " 'sevent',\n",
       " '▁sarcast',\n",
       " '▁ferling',\n",
       " '▁puertor',\n",
       " '▁portra',\n",
       " '▁incumb',\n",
       " '▁furthe',\n",
       " 'ababes',\n",
       " '▁persep',\n",
       " '▁headqu',\n",
       " '▁trival',\n",
       " '▁klat',\n",
       " '▁pentat',\n",
       " '▁boycot',\n",
       " 'vereign',\n",
       " 'akshana',\n",
       " 'mbann',\n",
       " '▁nabad',\n",
       " '▁graian',\n",
       " '▁mathem',\n",
       " '▁kown',\n",
       " 'ointed',\n",
       " '▁slobo',\n",
       " '▁leban',\n",
       " 'radurga',\n",
       " 'etery',\n",
       " '▁fatim',\n",
       " '▁aborig',\n",
       " 'avour',\n",
       " '▁alist',\n",
       " '▁thinn',\n",
       " '▁velk',\n",
       " 'aziland',\n",
       " '▁unequiv',\n",
       " 'istrian',\n",
       " '▁inaccur',\n",
       " '▁chipe',\n",
       " '▁cathe',\n",
       " 'omorets',\n",
       " '▁judg',\n",
       " '▁parasy',\n",
       " 'ibrium',\n",
       " '▁unimport',\n",
       " 'ortable',\n",
       " 'ajuwon',\n",
       " '▁proce',\n",
       " '▁yanco',\n",
       " '▁skyscrap',\n",
       " '▁wojs',\n",
       " '▁rerele',\n",
       " 'inness',\n",
       " 'artian',\n",
       " '▁testacea',\n",
       " 'ternal',\n",
       " '▁banglapedia',\n",
       " '▁indones',\n",
       " 'guatem',\n",
       " 'daemun',\n",
       " 'qsa',\n",
       " 'ihin',\n",
       " 'acters',\n",
       " '▁fortu',\n",
       " '▁waterlo',\n",
       " '▁semia',\n",
       " '▁graffitti',\n",
       " 'omercial',\n",
       " 'rph',\n",
       " 'edkar',\n",
       " '▁preb',\n",
       " 'ikep',\n",
       " 'icou',\n",
       " 'vernmental',\n",
       " 'ossos',\n",
       " '▁diacrit',\n",
       " '▁edific',\n",
       " '▁idios',\n",
       " '▁umba',\n",
       " 'owanie',\n",
       " '▁hdg',\n",
       " 'fairyt',\n",
       " '▁zsche',\n",
       " '▁gourn',\n",
       " 'abobo',\n",
       " 'jerem',\n",
       " 'thals',\n",
       " 'vayne',\n",
       " '▁involunt',\n",
       " '▁reconstr',\n",
       " '▁neway',\n",
       " '▁suspic',\n",
       " '▁terg',\n",
       " 'zczady',\n",
       " '▁rakon',\n",
       " 'ehaw',\n",
       " '▁kierz',\n",
       " '▁toget',\n",
       " '▁occas',\n",
       " 'ergen',\n",
       " '▁recreat',\n",
       " 'olphin',\n",
       " '▁datz',\n",
       " '▁nefar',\n",
       " '▁sium',\n",
       " 'theon',\n",
       " '▁assass',\n",
       " 'ategy',\n",
       " '▁commem',\n",
       " '▁phetch',\n",
       " '▁disgrunt',\n",
       " 'adhyay',\n",
       " '▁flameth',\n",
       " '▁nondesc',\n",
       " '▁diyarbak',\n",
       " '▁deprav',\n",
       " 'quois',\n",
       " 'ahisar',\n",
       " 'coursed',\n",
       " '▁theore',\n",
       " '▁crno',\n",
       " '▁algorith',\n",
       " 'atanatyam',\n",
       " 'ambro',\n",
       " '▁misanthrop',\n",
       " 'rekker',\n",
       " 'intendo',\n",
       " 'masquer',\n",
       " 'uggs',\n",
       " 'nane',\n",
       " '▁horiz',\n",
       " '▁syang',\n",
       " 'nabe',\n",
       " 'corhynchus',\n",
       " 'gujar',\n",
       " '▁horv',\n",
       " 'hentic',\n",
       " 'onday',\n",
       " '▁condol',\n",
       " '▁zarath',\n",
       " '▁embass',\n",
       " 'platan',\n",
       " 'helioma',\n",
       " 'ynastic',\n",
       " '▁bessarab']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(oov_list))\n",
    "oov_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class GRUClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, gru_dim=150, dense_dim=256, batch_size=128, epochs=2, bidirectional=False, \n",
    "                 pool_type='all', initial_weights=None, optimizer='adam' ,verbose=1, out_dim=6, callbacks=None,\n",
    "                spatial_drop=0.0, dropout=0.0, mask_zero=True, \n",
    "                gru_kernel_regularization = 0.0,\n",
    "                gru_recurrent_regularization = 0.0,\n",
    "                gru_bias_regularization = 0.0,\n",
    "                embeddings_regularization = 0.0,\n",
    "                ):\n",
    "        \n",
    "        self.gru_dim = gru_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs= epochs\n",
    "        self.bidirectional = bidirectional\n",
    "        self.pool_type = pool_type\n",
    "        self.initial_weights = initial_weights\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.optimizer = optimizer\n",
    "        self.out_dim = out_dim\n",
    "        self.spatial_drop = spatial_drop\n",
    "        self.dropout = dropout\n",
    "        self.mask_zero = mask_zero\n",
    "        self.gru_kernel_regularization = gru_kernel_regularization\n",
    "        self.gru_recurrent_regularization = gru_recurrent_regularization\n",
    "        self.gru_bias_regularization = gru_bias_regularization\n",
    "        self.embeddings_regularization = embeddings_regularization\n",
    "        \n",
    "    def _build_model(self):\n",
    "        inp = Input(shape=(MAX_LEN,))\n",
    "        emb = Embedding(MAX_FEATURES+1, \n",
    "                        EMBED_SIZE,\n",
    "                        weights=[self.initial_weights],\n",
    "                        mask_zero=self.mask_zero,\n",
    "                        #embeddings_regularizer=regularizers.l2(self.embeddings_regularization),\n",
    "                        trainable=True)(inp)\n",
    "\n",
    "        if self.mask_zero:\n",
    "            emb = ZeroMaskedLayer()(emb)\n",
    "         \n",
    "        #emb2 = Dot(axes=1)([emb, emb])\n",
    "        #print(emb.shape)\n",
    "        emb2 = SpatialDropout1D(self.spatial_drop)(emb)\n",
    "        if self.bidirectional:\n",
    "            enc = Bidirectional(CuDNNGRU(int(self.gru_dim), return_sequences=True, return_state=True, stateful=False,\n",
    "                                         ))(emb2)\n",
    "            x = enc[0]\n",
    "            state = enc[1]\n",
    "        else:\n",
    "            x, state = CuDNNGRU(int(self.gru_dim), return_sequences=True, return_state=True,\n",
    "                            kernel_regularizer=regularizers.l2(self.gru_kernel_regularization),\n",
    "                            recurrent_regularizer=regularizers.l2(self.gru_recurrent_regularization),\n",
    "                            bias_regularizer=regularizers.l2(self.gru_bias_regularization)\n",
    "                               )(emb2)\n",
    "            #x = SpatialDropout1D(0.5)(x)\n",
    "        \n",
    "        if self.pool_type == 'avg':\n",
    "            x = GlobalAveragePooling1D()(x)\n",
    "            x = concatenate([x, state])\n",
    "            \n",
    "        elif self.pool_type == 'max':\n",
    "            x = GlobalMaxPool1D()(x)\n",
    "            x = concatenate([x, state])\n",
    "            \n",
    "        elif self.pool_type == 'attn':\n",
    "            x = AttentionLayer(MAX_LEN)(x)\n",
    "            x = concatenate([x, state])\n",
    "            \n",
    "        elif self.pool_type == 'all':\n",
    "            #x1 = GlobalAveragePooling1D()(emb2)\n",
    "            #x2 = GlobalAveragePooling1D()(x)\n",
    "            #x3 = GlobalAveragePooling1D()(emb)\n",
    "            x4 = GlobalMaxPool1D()(x)\n",
    "            x5 = AttentionLayer(MAX_LEN)(x)\n",
    "            x = concatenate([x5, x4])\n",
    "    \n",
    "        x = Dropout(self.dropout)(x)\n",
    "        x = Dense(self.dense_dim)(x)\n",
    "        x = PReLU()(x)\n",
    "        \n",
    "        #x = Dense(600)(x)\n",
    "        #x = PReLU()(x)\n",
    "\n",
    "        out = Dense(self.out_dim, activation=\"sigmoid\")(x)\n",
    "        if self.optimizer == 'adam':\n",
    "            opt = Adam(lr=0.001, decay=0.0, clipnorm=1.0)\n",
    "        elif self.optimizer == 'rmsprop':\n",
    "            opt = RMSprop(clipnorm=1.0)\n",
    "        model = Model(inputs=inp, outputs=out)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "        if self.callbacks:\n",
    "            self.model.fit(X, y, batch_size=self.batch_size, epochs=self.epochs,\n",
    "                       verbose=self.verbose,\n",
    "                       callbacks=self.callbacks,\n",
    "                       shuffle=True)\n",
    "        else:\n",
    "            self.model.fit(X, y, batch_size=self.batch_size, epochs=self.epochs,\n",
    "                       verbose=self.verbose,\n",
    "                       shuffle=True)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        if self.model:\n",
    "            y_hat = self.model.predict(X, batch_size=1024)\n",
    "        else:\n",
    "            raise ValueError(\"Model not fit yet\")\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_decay(epoch):\n",
    "    if epoch == 0:\n",
    "        return 0.0016\n",
    "    if epoch == 1:\n",
    "        return 0.00024\n",
    "    if epoch == 2:\n",
    "        return 0.001\n",
    "    if epoch == 3:\n",
    "        return 0.00001\n",
    "\n",
    "\n",
    "def shuffle_crossvalidator(model, cvlist, X, y, lr_decay):\n",
    "    y_trues = []\n",
    "    y_preds = []\n",
    "    scores = []\n",
    "    LRDecay = LearningRateScheduler(lr_decay)\n",
    "\n",
    "    for tr_index, val_index in cvlist:\n",
    "        X_tr, y_tr = X[tr_index, :], y[tr_index, :]\n",
    "        X_val, y_val = X[val_index, :], y[val_index, :]\n",
    "        RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "\n",
    "        model.set_params(**{'callbacks':[RocAuc, LRDecay]})\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        score = roc_auc_score(y_val, y_pred)\n",
    "        scores.append(score)\n",
    "        print(\"ROC AUC for this fold is \", score)\n",
    "        y_trues.append(y_val)\n",
    "        y_preds.append(y_pred)\n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "        #break\n",
    "    y_trues = np.concatenate(y_trues)\n",
    "    y_preds = np.concatenate(y_preds)\n",
    "    score = roc_auc_score(y_trues, y_preds)\n",
    "    print(\"Overall score on 10 fold CV is {}\".format(score))\n",
    "    \n",
    "    return y_preds, y_trues, scores\n",
    "\n",
    "def outoffold_crossvalidator(model_params, cvlist, X, y, lr_decay):\n",
    "    y_preds = np.zeros(y.shape)\n",
    "    LRDecay = LearningRateScheduler(lr_decay)\n",
    "\n",
    "    for tr_index, val_index in cvlist:\n",
    "        X_tr, y_tr = X[tr_index, :], y[tr_index, :]\n",
    "        X_val, y_val = X[val_index, :], y[val_index, :]\n",
    "        RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "        \n",
    "        model.set_params(**{'callbacks':[RocAuc, LRDecay]})\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        print(\"ROC AUC for this fold is \", roc_auc_score(y_val, y_pred))\n",
    "        y_preds[val_idx] = y_pred\n",
    "        K.clear_session()\n",
    "        break\n",
    "    score = roc_auc_score(y, y_preds)\n",
    "    print(\"Overall score on 10 fold CV is {}\".format(score))\n",
    "    \n",
    "    return y_preds, y_trues, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "151488/151592 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9813\n",
      " ROC-AUC - epoch: 1 - score: 0.989571 \n",
      "\n",
      "151592/151592 [==============================] - 96s 636us/step - loss: 0.0507 - acc: 0.9813\n",
      "Epoch 2/2\n",
      "151488/151592 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9862\n",
      " ROC-AUC - epoch: 2 - score: 0.990403 \n",
      "\n",
      "151592/151592 [==============================] - 97s 638us/step - loss: 0.0338 - acc: 0.9862\n",
      "ROC AUC for this fold is  0.9904027520417942\n",
      "Epoch 1/2\n",
      "151488/151592 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9813\n",
      " ROC-AUC - epoch: 1 - score: 0.989074 \n",
      "\n",
      "151592/151592 [==============================] - 97s 639us/step - loss: 0.0508 - acc: 0.9813\n",
      "Epoch 2/2\n",
      "151488/151592 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9859\n",
      " ROC-AUC - epoch: 2 - score: 0.990222 \n",
      "\n",
      "151592/151592 [==============================] - 97s 639us/step - loss: 0.0344 - acc: 0.9859\n",
      "ROC AUC for this fold is  0.9902219043610222\n",
      "Epoch 1/2\n",
      "151488/151592 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9812\n",
      " ROC-AUC - epoch: 1 - score: 0.987388 \n",
      "\n",
      "151592/151592 [==============================] - 97s 639us/step - loss: 0.0509 - acc: 0.9812\n",
      "Epoch 2/2\n",
      "151488/151592 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9863\n",
      " ROC-AUC - epoch: 2 - score: 0.988239 \n",
      "\n",
      "151592/151592 [==============================] - 97s 638us/step - loss: 0.0337 - acc: 0.9863\n",
      "ROC AUC for this fold is  0.9882387141752084\n",
      "Epoch 1/2\n",
      "151488/151592 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9813\n",
      " ROC-AUC - epoch: 1 - score: 0.988585 \n",
      "\n",
      "151592/151592 [==============================] - 97s 638us/step - loss: 0.0510 - acc: 0.9813\n",
      "Epoch 2/2\n",
      "151488/151592 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9860\n",
      " ROC-AUC - epoch: 2 - score: 0.990234 \n",
      "\n",
      "151592/151592 [==============================] - 97s 638us/step - loss: 0.0342 - acc: 0.9860\n",
      "ROC AUC for this fold is  0.9902338683768446\n",
      "Epoch 1/2\n",
      "151488/151592 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9814\n",
      " ROC-AUC - epoch: 1 - score: 0.986473 \n",
      "\n",
      "151592/151592 [==============================] - 97s 639us/step - loss: 0.0506 - acc: 0.9814\n",
      "Epoch 2/2\n",
      "151488/151592 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9861\n",
      " ROC-AUC - epoch: 2 - score: 0.988387 \n",
      "\n",
      "151592/151592 [==============================] - 97s 639us/step - loss: 0.0343 - acc: 0.9861\n",
      "ROC AUC for this fold is  0.988387324593393\n",
      "Overall score on 10 fold CV is 0.989193948914337\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def lr_decay(epoch):\n",
    "    if epoch == 0:\n",
    "        return 0.0015\n",
    "    if epoch == 1:\n",
    "        return 0.0003\n",
    "    if epoch == 2:\n",
    "        return 0.001\n",
    "    if epoch == 3:\n",
    "        return 0.001\n",
    "    if epoch == 4:\n",
    "        return 0.001\n",
    "    if epoch == 5:\n",
    "        return 0.001\n",
    "    return 0.001\n",
    "\n",
    "K.clear_session()\n",
    "#config = tf.ConfigProto(\n",
    "#        device_count = {'GPU': 1}\n",
    "#    )\n",
    "#sess = tf.Session(config=config)\n",
    "model = GRUClassifier(gru_dim=300, dense_dim=600, initial_weights=embedding_matrix, bidirectional=True,\n",
    "                    batch_size=64, epochs=2, optimizer='adam', pool_type='all', dropout=0.2, spatial_drop=0.3, mask_zero=False)\n",
    "\n",
    "y_preds, y_trues, _ = shuffle_crossvalidator(model, cvlist2, X_train, y, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "gc.collect()\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_list = [{'batch_size': [47.0],\n",
    "  'bidirectional': [0],\n",
    "  'dense_dim': [973.0],\n",
    "  'dropout': [0.19862535182199834],\n",
    "  'gru_bias_reg': [1.011936859273273e-08],\n",
    "  'gru_dim': [358.0],\n",
    "  'gru_kernel_reg': [2.0678669679829352e-10],\n",
    "  'gru_recc_reg': [8.946942716621634e-07],\n",
    "  'lr1': [0.0015982451490776767],\n",
    "  'lr2': [0.0002459290205687559],\n",
    "  'mask_zero': [1],\n",
    "  'optimizer': [0],\n",
    "  'pool_type': [3],\n",
    "  'spatial_drop': [0.2696100622336198]},\n",
    " {'batch_size': [83.0],\n",
    "  'bidirectional': [0],\n",
    "  'dense_dim': [351.0],\n",
    "  'dropout': [0.07833431778315075],\n",
    "  'gru_bias_reg': [1.989216237371643e-09],\n",
    "  'gru_dim': [478.0],\n",
    "  'gru_kernel_reg': [2.1606860352426398e-10],\n",
    "  'gru_recc_reg': [1.6736919208281796e-07],\n",
    "  'lr1': [0.00263784102869703],\n",
    "  'lr2': [0.0005711207564167526],\n",
    "  'mask_zero': [1],\n",
    "  'optimizer': [0],\n",
    "  'pool_type': [3],\n",
    "  'spatial_drop': [0.21401382410917008]},\n",
    " {'batch_size': [49.0],\n",
    "  'bidirectional': [0],\n",
    "  'dense_dim': [997.0],\n",
    "  'dropout': [0.19115533803668047],\n",
    "  'gru_bias_reg': [5.222640591389245e-10],\n",
    "  'gru_dim': [399.0],\n",
    "  'gru_kernel_reg': [8.078459790975857e-10],\n",
    "  'gru_recc_reg': [6.100081276448957e-08],\n",
    "  'lr1': [0.0019427338445684181],\n",
    "  'lr2': [0.00010186610979091696],\n",
    "  'mask_zero': [1],\n",
    "  'optimizer': [0],\n",
    "  'pool_type': [3],\n",
    "  'spatial_drop': [0.22614208466560007]},\n",
    " {'batch_size': [41.0],\n",
    "  'bidirectional': [0],\n",
    "  'dense_dim': [973.0],\n",
    "  'dropout': [0.20050865242539928],\n",
    "  'gru_bias_reg': [1.1451922219328368e-08],\n",
    "  'gru_dim': [392.0],\n",
    "  'gru_kernel_reg': [1.0516629869555607e-09],\n",
    "  'gru_recc_reg': [1.2593577396164419e-06],\n",
    "  'lr1': [0.0016205788115723873],\n",
    "  'lr2': [0.00011538601448660545],\n",
    "  'mask_zero': [1],\n",
    "  'optimizer': [0],\n",
    "  'pool_type': [3],\n",
    "  'spatial_drop': [0.3803897135211322]},\n",
    " {'batch_size': [37.0],\n",
    "  'bidirectional': [0],\n",
    "  'dense_dim': [237.0],\n",
    "  'dropout': [0.12273937792021693],\n",
    "  'gru_bias_reg': [2.7055793227129377e-09],\n",
    "  'gru_dim': [407.0],\n",
    "  'gru_kernel_reg': [1.9122269544090935e-09],\n",
    "  'gru_recc_reg': [1.5269966614646778e-06],\n",
    "  'lr1': [0.0019545667587842147],\n",
    "  'lr2': [0.00034205962093229346],\n",
    "  'mask_zero': [1],\n",
    "  'optimizer': [0],\n",
    "  'pool_type': [3],\n",
    "  'spatial_drop': [0.239366738134983]},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "143585/143593 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9812\n",
      " ROC-AUC - epoch: 1 - score: 0.985494 \n",
      "\n",
      "143593/143593 [==============================] - 168s 1ms/step - loss: 0.0507 - acc: 0.9812\n",
      "Epoch 2/2\n",
      "143585/143593 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9864\n",
      " ROC-AUC - epoch: 2 - score: 0.986598 \n",
      "\n",
      "143593/143593 [==============================] - 168s 1ms/step - loss: 0.0332 - acc: 0.9864\n",
      "ROC AUC for this fold is  0.9865982493060157\n",
      "Epoch 1/2\n",
      "143585/143600 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9813\n",
      " ROC-AUC - epoch: 1 - score: 0.986314 \n",
      "\n",
      "143600/143600 [==============================] - 168s 1ms/step - loss: 0.0506 - acc: 0.9813\n",
      "Epoch 2/2\n",
      "143585/143600 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9864\n",
      " ROC-AUC - epoch: 2 - score: 0.987023 \n",
      "\n",
      "143600/143600 [==============================] - 168s 1ms/step - loss: 0.0335 - acc: 0.9864\n",
      "ROC AUC for this fold is  0.9870233444184867\n",
      "Epoch 1/2\n",
      "143585/143603 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9814\n",
      " ROC-AUC - epoch: 1 - score: 0.986948 \n",
      "\n",
      "143603/143603 [==============================] - 168s 1ms/step - loss: 0.0509 - acc: 0.9814\n",
      "Epoch 2/2\n",
      "143585/143603 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9863\n",
      " ROC-AUC - epoch: 2 - score: 0.988438 \n",
      "\n",
      "143603/143603 [==============================] - 168s 1ms/step - loss: 0.0335 - acc: 0.9863\n",
      "ROC AUC for this fold is  0.9884377331134698\n",
      "Epoch 1/2\n",
      "143585/143608 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9813\n",
      " ROC-AUC - epoch: 1 - score: 0.986578 \n",
      "\n",
      "143608/143608 [==============================] - 168s 1ms/step - loss: 0.0510 - acc: 0.9813\n",
      "Epoch 2/2\n",
      "143585/143608 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9863\n",
      " ROC-AUC - epoch: 2 - score: 0.988573 \n",
      "\n",
      "143608/143608 [==============================] - 168s 1ms/step - loss: 0.0335 - acc: 0.9863\n",
      "ROC AUC for this fold is  0.988572557935017\n",
      "Epoch 1/2\n",
      "143585/143613 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9812\n",
      " ROC-AUC - epoch: 1 - score: 0.985507 \n",
      "\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.0511 - acc: 0.9812\n",
      "Epoch 2/2\n",
      "143585/143613 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9863\n",
      " ROC-AUC - epoch: 2 - score: 0.987536 \n",
      "\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.0335 - acc: 0.9863\n",
      "ROC AUC for this fold is  0.9875364667823487\n",
      "Epoch 1/2\n",
      "143585/143616 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9814\n",
      " ROC-AUC - epoch: 1 - score: 0.987240 \n",
      "\n",
      "143616/143616 [==============================] - 168s 1ms/step - loss: 0.0506 - acc: 0.9814\n",
      "Epoch 2/2\n",
      "143585/143616 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9864\n",
      " ROC-AUC - epoch: 2 - score: 0.988611 \n",
      "\n",
      "143616/143616 [==============================] - 168s 1ms/step - loss: 0.0335 - acc: 0.9864\n",
      "ROC AUC for this fold is  0.9886119001844679\n",
      "Epoch 1/2\n",
      "143585/143621 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9814\n",
      " ROC-AUC - epoch: 1 - score: 0.987497 \n",
      "\n",
      "143621/143621 [==============================] - 168s 1ms/step - loss: 0.0507 - acc: 0.9814\n",
      "Epoch 2/2\n",
      "143585/143621 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9862\n",
      " ROC-AUC - epoch: 2 - score: 0.989103 \n",
      "\n",
      "143621/143621 [==============================] - 168s 1ms/step - loss: 0.0337 - acc: 0.9862\n",
      "ROC AUC for this fold is  0.9891026164981386\n",
      "Epoch 1/2\n",
      "143585/143624 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9813\n",
      " ROC-AUC - epoch: 1 - score: 0.984296 \n",
      "\n",
      "143624/143624 [==============================] - 168s 1ms/step - loss: 0.0511 - acc: 0.9813\n",
      "Epoch 2/2\n",
      "143585/143624 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9865\n",
      " ROC-AUC - epoch: 2 - score: 0.986654 \n",
      "\n",
      "143624/143624 [==============================] - 167s 1ms/step - loss: 0.0334 - acc: 0.9865\n",
      "ROC AUC for this fold is  0.9866537931441107\n",
      "Epoch 1/2\n",
      "143585/143630 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9813\n",
      " ROC-AUC - epoch: 1 - score: 0.987806 \n",
      "\n",
      "143630/143630 [==============================] - 168s 1ms/step - loss: 0.0510 - acc: 0.9813\n",
      "Epoch 2/2\n",
      "143585/143630 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9863\n",
      " ROC-AUC - epoch: 2 - score: 0.990776 \n",
      "\n",
      "143630/143630 [==============================] - 167s 1ms/step - loss: 0.0335 - acc: 0.9863\n",
      "ROC AUC for this fold is  0.9907755445450944\n",
      "Epoch 1/2\n",
      "143585/143631 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9813\n",
      " ROC-AUC - epoch: 1 - score: 0.985719 \n",
      "\n",
      "143631/143631 [==============================] - 168s 1ms/step - loss: 0.0513 - acc: 0.9813\n",
      "Epoch 2/2\n",
      "143585/143631 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9859\n",
      " ROC-AUC - epoch: 2 - score: 0.987245 \n",
      "\n",
      "143631/143631 [==============================] - 168s 1ms/step - loss: 0.0346 - acc: 0.9859\n",
      "ROC AUC for this fold is  0.987244809629157\n",
      "Shape of test _preds is  (153164, 6)\n",
      "Means of val and test preds are [0.09482472 0.01027475 0.05241129 0.00260243 0.04778546 0.00847952] and [0.21880746 0.01877851 0.12917855 0.00489066 0.10245325 0.01901295]\n",
      "Overall score on 10 fold CV is 0.9875574585296875\n",
      "Epoch 1/2\n",
      "143590/143593 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9811\n",
      " ROC-AUC - epoch: 1 - score: 0.985322 \n",
      "\n",
      "143593/143593 [==============================] - 138s 963us/step - loss: 0.0508 - acc: 0.9811\n",
      "Epoch 2/2\n",
      "143590/143593 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9869\n",
      " ROC-AUC - epoch: 2 - score: 0.985968 \n",
      "\n",
      "143593/143593 [==============================] - 138s 963us/step - loss: 0.0320 - acc: 0.9869\n",
      "ROC AUC for this fold is  0.9859681605834183\n",
      "Epoch 1/2\n",
      "143590/143600 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9809\n",
      " ROC-AUC - epoch: 1 - score: 0.984072 \n",
      "\n",
      "143600/143600 [==============================] - 139s 969us/step - loss: 0.0532 - acc: 0.9809\n",
      "Epoch 2/2\n",
      "136203/143600 [===========================>..] - ETA: 6s - loss: 0.0336 - acc: 0.9865"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-79e80778fe59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0my_test_preds_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0my_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0my_preds_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0my_trues_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_trues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-179-79e80778fe59>\u001b[0m in \u001b[0;36mtrain_predict\u001b[0;34m(parameter_space)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m#y_preds, y_trues, y_test_preds = shuffle_train_predict(model, cvlist2, X_train, y, X_test, lr_decay)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0my_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moof_train_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcvlist1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-179-79e80778fe59>\u001b[0m in \u001b[0;36moof_train_predict\u001b[0;34m(model, cvlist, X, y, X_test, lr_decay)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'callbacks'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRocAuc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLRDecay\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-170-a46c8cb9bd83>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    100\u001b[0m                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                        \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                        shuffle=True)\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             self.model.fit(X, y, batch_size=self.batch_size, epochs=self.epochs,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Pick top 10 parameter settings, Bag models for those settings\n",
    "#Try linear blending on those settings\n",
    "#NUM_BAGS = 10\n",
    "#cvlist3 = list(StratifiedShuffleSplit(n_splits=NUM_BAGS, test_size=0.05, random_state=786).split(y, y[:,2]))\n",
    "\n",
    "\n",
    "def shuffle_train_predict(model, cvlist, X, y, X_test, lr_decay):\n",
    "    y_trues = []\n",
    "    y_preds = []\n",
    "    y_test_preds = []\n",
    "    scores = []\n",
    "    LRDecay = LearningRateScheduler(lr_decay)\n",
    "\n",
    "    for tr_index, val_index in cvlist:\n",
    "        X_tr, y_tr = X[tr_index, :], y[tr_index, :]\n",
    "        X_val, y_val = X[val_index, :], y[val_index, :]\n",
    "        RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "\n",
    "        model.set_params(**{'callbacks':[RocAuc, LRDecay]})\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        score = roc_auc_score(y_val, y_pred)\n",
    "        scores.append(score)\n",
    "        print(\"ROC AUC for this fold is \", score)\n",
    "        y_trues.append(y_val)\n",
    "        y_preds.append(y_pred)\n",
    "        y_test_preds.append(y_test_pred)\n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "        #break\n",
    "    y_trues = np.concatenate(y_trues)\n",
    "    y_preds = np.concatenate(y_preds)\n",
    "    y_test_preds = np.mean(y_test_preds, axis=0)\n",
    "    print(\"Shape of test _preds is \", y_test_preds.shape)\n",
    "    print(\"Means of val and test preds are {} and {}\".format(np.mean(y_preds, axis=1), np.mean(y_test_preds, axis=1)))\n",
    "    score = roc_auc_score(y_trues, y_preds)\n",
    "    print(\"Overall score on 10 fold CV is {}\".format(score))\n",
    "    \n",
    "    return y_preds, y_trues, y_test_preds\n",
    "\n",
    "def oof_train_predict(model, cvlist, X, y, X_test, lr_decay):\n",
    "    #y_trues = []\n",
    "    y_test_preds = []\n",
    "    scores = []\n",
    "    y_preds = np.zeros(y.shape)\n",
    "    LRDecay = LearningRateScheduler(lr_decay)\n",
    "\n",
    "    for tr_index, val_index in cvlist:\n",
    "        X_tr, y_tr = X[tr_index, :], y[tr_index, :]\n",
    "        X_val, y_val = X[val_index, :], y[val_index, :]\n",
    "        RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "\n",
    "        model.set_params(**{'callbacks':[RocAuc, LRDecay]})\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        score = roc_auc_score(y_val, y_pred)\n",
    "        scores.append(score)\n",
    "        print(\"ROC AUC for this fold is \", score)\n",
    "        #y_trues.append(y_val)\n",
    "        y_preds[val_index, :] = y_pred\n",
    "        y_test_preds.append(y_test_pred)\n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "        #break\n",
    "    #y_trues = np.concatenate(y_trues)\n",
    "    #y_preds = np.concatenate(y_preds)\n",
    "    y_test_preds = np.mean(y_test_preds, axis=0)\n",
    "    print(\"Shape of test _preds is \", y_test_preds.shape)\n",
    "    print(\"Means of val and test preds are {} and {}\".format(np.mean(y_preds, axis=0), np.mean(y_test_preds, axis=0)))\n",
    "    score = roc_auc_score(y, y_preds)\n",
    "    print(\"Overall score on 10 fold CV is {}\".format(score))\n",
    "    \n",
    "    return y_preds, y_test_preds\n",
    "\n",
    "def train_predict(parameter_space):\n",
    "    \n",
    "    def lr_decay(epoch):\n",
    "        if epoch == 0:\n",
    "            return parameter_space['lr1'][0]\n",
    "        if epoch == 1:\n",
    "            return parameter_space['lr2'][0]\n",
    "    \n",
    "    model = GRUClassifier(initial_weights=embedding_matrix, bidirectional=[True, False][parameter_space['bidirectional'][0]],\n",
    "                          gru_dim = int(parameter_space['gru_dim'][0]),\n",
    "                          dense_dim = int(parameter_space['dense_dim'][0]),\n",
    "                          mask_zero = [True, False][parameter_space['mask_zero'][0]],\n",
    "                          pool_type = ['avg', 'max', 'attn', 'all'][parameter_space['pool_type'][0]],\n",
    "                          batch_size= int(parameter_space['batch_size'][0]), \n",
    "                          epochs=2, \n",
    "                          optimizer=[\"adam\", \"rmsprop\"][parameter_space['optimizer'][0]],\n",
    "                          dropout=parameter_space['dropout'][0],\n",
    "                          spatial_drop=parameter_space['spatial_drop'][0],\n",
    "                          gru_kernel_regularization = parameter_space[\"gru_kernel_reg\"][0],\n",
    "                          gru_recurrent_regularization = parameter_space[\"gru_recc_reg\"][0],\n",
    "                          gru_bias_regularization = parameter_space[\"gru_bias_reg\"][0],\n",
    "                          #embeddings_regularization = parameter_space[\"embeddings_reg\"],\n",
    "                          )\n",
    "\n",
    "    #y_preds, y_trues, y_test_preds = shuffle_train_predict(model, cvlist2, X_train, y, X_test, lr_decay) \n",
    "    y_preds, y_test_preds = oof_train_predict(model, cvlist1, X_train, y, X_test, lr_decay)\n",
    "    return y_preds, y_trues, y_test_preds\n",
    "\n",
    "#####\n",
    "y_preds_all = []\n",
    "y_trues_all = []\n",
    "y_test_preds_all = []\n",
    "for params in parameter_list:\n",
    "    y_preds, y_trues, y_test_preds = train_predict(params)\n",
    "    y_preds_all.append(y_preds)\n",
    "    y_trues_all.append(y_trues)\n",
    "    y_test_preds_all.append(y_test_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check corelation between different predictions\n",
    "#np.corrcoef(y_preds_all, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9875574585296875\n"
     ]
    }
   ],
   "source": [
    "#Try different stacking approaches\n",
    "from scipy.stats import gmean, hmean\n",
    "\n",
    "preds_mean = gmean(y_preds_all, axis=0)\n",
    "print(roc_auc_score(y, preds_mean))\n",
    "test_preds_mean = gmean(y_test_preds_all, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = test_preds_mean\n",
    "sample_submission.to_csv('../input/gru_spemb_5bags_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
