{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial kernel based on different RNN layers\n",
    "\n",
    "* **Text preprocessing**\n",
    "\n",
    "Following things to be tried on the baseline:\n",
    "    * Add Early Stopping callback\n",
    "    * Increase max epochs - let EarlyStop do the work\n",
    "    * Add Tensorboard callback, monitor training\n",
    "    * Replace LSTM by GRU units and check if it changes anything\n",
    "    * Add another layer of LSTM/GRU, see if things improve\n",
    "    * Play around with Dense layers (add/# units/etc.)\n",
    "    * Find preprocessing rules you could add to improve the quality of the data\n",
    "    * Use different embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, Permute, GRU, Conv1D, LSTM, Embedding, Dropout, Activation, CuDNNLSTM, CuDNNGRU, concatenate, Flatten\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalAveragePooling1D, BatchNormalization, SpatialDropout1D, Dot\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "import keras.backend as K\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from functools import reduce\n",
    "from keras.layers import Layer, PReLU, SpatialDropout1D\n",
    "from keras import initializers\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../input/'\n",
    "utility_path = '../utility/'\n",
    "comp = 'jigsaw-toxic-comment-classification-challenge/'\n",
    "EMBEDDING_FILE=f'{utility_path}glove.42B.300d.txt'\n",
    "TRAIN_DATA_FILE=f'{path}train.csv'\n",
    "TEST_DATA_FILE=f'{path}test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN_DATA_FILE)\n",
    "test = pd.read_csv(TEST_DATA_FILE)\n",
    "\n",
    "train[\"comment_text\"] = train[\"comment_text\"].replace(\"\\[.?!]{1,}\\s\", \" <eos> \").replace(\"\\n\\n\", \" <eop> \").replace(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",\"\")\n",
    "test[\"comment_text\"] = test[\"comment_text\"].replace(\"\\[.?!]{1,}\\s\", \" <eos> \").replace(\"\\n\\n\", \" <eop> \").replace(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",\"\")\n",
    "\n",
    "list_sentences_train = train[\"comment_text\"].fillna(\"_na_\").values\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[list_classes].values\n",
    "list_sentences_test = test[\"comment_text\"].fillna(\"_na_\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 200000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 200 # max number of words in a comment to use\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features, char_level=False)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,   147,     6,   438,  3984,  1308,     4,  1205,    34,\n",
       "          35,  2200,   385,     1,    71,   550,   272,  1499,  4162,\n",
       "         520,   291,   168,     2, 12977,    20,   621,    11,    44,\n",
       "        1051,    97,    11,   151,    49,     6,    19,  2363,    20,\n",
       "         581,    17,    30,   336,    89,     1,    71,   550,     8,\n",
       "         502,    13,     8,   292,     1,   534,   135,  3312,    36,\n",
       "        1128,  8224,    52,   481,    17,     3,  1341,    66,  3940,\n",
       "           8,   316,   143,    52,     8,     1,    77,   832,  3212,\n",
       "        1272,    62,    87,    14,  4879,   205,   546,    57,   316,\n",
       "          93,    66, 34849,    30, 96149,  8544,     7,  2512,     2,\n",
       "         360,    13,    71,    10,  5445,     3, 15191,     1,   744,\n",
       "           3,    30,   336,     9,     8,  1242,     2,   151,    34,\n",
       "           1,   258,   550,     4,    14,  2648,  1308,   324,   383,\n",
       "          37, 14509,   384,    22,     6,  3226,     5,   816,     3,\n",
       "        1904,   128,     6,    40,    33,    13,    58,    40,    18,\n",
       "           5,  3821,   137,    15,     1,   440,     4,  2115,     1,\n",
       "         335, 15192], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Keras Layer that implements an Attention mechanism for temporal data.\n",
    "        Supports Masking.\n",
    "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
    "        # Input shape\n",
    "            3D tensor with shape: `(samples, steps, features)`.\n",
    "        # Output shape\n",
    "            2D tensor with shape: `(samples, features)`.\n",
    "        :param kwargs:\n",
    "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "        The dimensions are inferred based on the output shape of the RNN.\n",
    "        Example:\n",
    "            model.add(LSTM(64, return_sequences=True))\n",
    "            model.add(Attention())\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        # self.init = initializations.get('glorot_uniform')\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # eij = K.dot(x, self.W) TF backend doesn't support it\n",
    "\n",
    "        # features_dim = self.W.shape[0]\n",
    "        # step_dim = x._keras_shape[1]\n",
    "\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))),\n",
    "                        (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        # print weigthted_input.shape\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # return input_shape[0], input_shape[-1]\n",
    "        return input_shape[0], self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "train['target_str'] = reduce(lambda x,y: x+y, [train[col].astype(str) for col in label_cols])\n",
    "train['target_str'] = train['target_str'].replace('110101', '000000').replace('110110','000000')\n",
    "cvlist = list(StratifiedShuffleSplit(n_splits=5, test_size=0.05, random_state=786).split(train, train['target_str'].astype('category')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "np.random.seed(1)\n",
    "#tf.random_seed(1)\n",
    "def train_gru(params):\n",
    "    embed_size, gru_dim, dense_dim, lr1 , lr2, decay, batch_size = params\n",
    "    \n",
    "    def lr_decay(epoch):\n",
    "        if epoch == 0:\n",
    "            return lr1\n",
    "        if epoch == 1:\n",
    "            return lr2\n",
    "        if epoch == 2:\n",
    "            return 0.001\n",
    "        if epoch == 3:\n",
    "            return 0.00001\n",
    "        \n",
    "    def get_model():\n",
    "        inp = Input(shape=(maxlen,))\n",
    "        emb = Embedding(max_features, embed_size,\n",
    "                     )(inp)\n",
    "        print(emb.shape)\n",
    "        emb = SpatialDropout1D(0.5)(emb)\n",
    "        tmp = Bidirectional(CuDNNGRU(int(gru_dim), return_sequences=True, return_state=True))(emb)\n",
    "        x2 = tmp[0]\n",
    "        state = tmp[1]\n",
    "        x3 = Attention(maxlen)(x2)\n",
    "        x4 = GlobalAveragePooling1D()(x2)\n",
    "\n",
    "        x = concatenate([x3, x4, state])\n",
    "        #x = avg_pool\n",
    "        #x = BatchNormalization()(x)\n",
    "        #x = Dropout(0.2)(x)\n",
    "        x = Dense(dense_dim)(x)\n",
    "        x = PReLU()(x)\n",
    "\n",
    "        #x = BatchNormalization()(x)\n",
    "        #x = Dropout(0.2)(x)\n",
    "        #x = Dense(64)(x)\n",
    "        #x = PReLU()(x)\n",
    "        #x = Dropout(0.1)(x)\n",
    "        out = Dense(6, activation=\"sigmoid\")(x)\n",
    "        opt = Adam(lr=0.001, decay=decay)\n",
    "        model = Model(inputs=inp, outputs=out)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    y_trues = []\n",
    "    y_preds = []\n",
    "    LRDecay = LearningRateScheduler(lr_decay)\n",
    "    for tr_index, val_index in cvlist:\n",
    "        X_train, y_train = X_t[tr_index, :], y[tr_index, :]\n",
    "        X_val, y_val = X_t[val_index, :], y[val_index, :]\n",
    "        RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "        model = get_model()\n",
    "        model.fit(X_train, y_train, batch_size=batch_size, epochs=2, validation_split=0.0, verbose=1, \n",
    "                  callbacks=[RocAuc, LRDecay])\n",
    "        y_pred = model.predict(X_val, batch_size=2048)\n",
    "        print(\"ROC AUC for this fold is \", roc_auc_score(y_val, y_pred))\n",
    "        y_trues.append(y_val)\n",
    "        y_preds.append(y_pred)\n",
    "        K.clear_session()\n",
    "        \n",
    "    score = -roc_auc_score(np.concatenate(y_trues), np.concatenate(y_preds))\n",
    "    print(\"Overall score with params {} is {}\".format(params, score))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train_gru()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skopt\n",
    "from skopt import gp_minimize, gbrt_minimize\n",
    "from skopt.space import Real, Integer, Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 200, 188)\n",
      "Epoch 1/2\n",
      "151389/151592 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9795\n",
      " ROC-AUC - epoch: 1 - score: 0.982213 \n",
      "\n",
      "151592/151592 [==============================] - 36s 237us/step - loss: 0.0621 - acc: 0.9795\n",
      "Epoch 2/2\n",
      "151389/151592 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9857\n",
      " ROC-AUC - epoch: 2 - score: 0.983151 \n",
      "\n",
      "151592/151592 [==============================] - 36s 238us/step - loss: 0.0364 - acc: 0.9857\n",
      "ROC AUC for this fold is  0.9831507887571517\n",
      "(?, 200, 188)\n",
      "Epoch 1/2\n",
      "151389/151592 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9793\n",
      " ROC-AUC - epoch: 1 - score: 0.982551 \n",
      "\n",
      "151592/151592 [==============================] - 36s 234us/step - loss: 0.0624 - acc: 0.9793\n",
      "Epoch 2/2\n",
      "151389/151592 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9855\n",
      " ROC-AUC - epoch: 2 - score: 0.984904 \n",
      "\n",
      "151592/151592 [==============================] - 36s 234us/step - loss: 0.0368 - acc: 0.9855\n",
      "ROC AUC for this fold is  0.9849042706445514\n",
      "(?, 200, 188)\n",
      "Epoch 1/2\n",
      "151389/151592 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9789\n",
      " ROC-AUC - epoch: 1 - score: 0.978703 \n",
      "\n",
      "151592/151592 [==============================] - 36s 236us/step - loss: 0.0632 - acc: 0.9789\n",
      "Epoch 2/2\n",
      "151389/151592 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9854\n",
      " ROC-AUC - epoch: 2 - score: 0.981460 \n",
      "\n",
      "151592/151592 [==============================] - 36s 235us/step - loss: 0.0367 - acc: 0.9854\n",
      "ROC AUC for this fold is  0.981459628816375\n",
      "(?, 200, 188)\n",
      "Epoch 1/2\n",
      "151389/151592 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9790\n",
      " ROC-AUC - epoch: 1 - score: 0.983140 \n",
      "\n",
      "151592/151592 [==============================] - 36s 239us/step - loss: 0.0627 - acc: 0.9790\n",
      "Epoch 2/2\n",
      "151389/151592 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9854\n",
      " ROC-AUC - epoch: 2 - score: 0.985088 \n",
      "\n",
      "151592/151592 [==============================] - 36s 239us/step - loss: 0.0367 - acc: 0.9854\n",
      "ROC AUC for this fold is  0.985088204547639\n",
      "(?, 200, 188)\n",
      "Epoch 1/2\n",
      "151389/151592 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9792\n",
      " ROC-AUC - epoch: 1 - score: 0.972825 \n",
      "\n",
      "151592/151592 [==============================] - 36s 240us/step - loss: 0.0623 - acc: 0.9792\n",
      "Epoch 2/2\n",
      "151389/151592 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9855\n",
      " ROC-AUC - epoch: 2 - score: 0.978548 \n",
      "\n",
      "151592/151592 [==============================] - 36s 239us/step - loss: 0.0367 - acc: 0.9855\n",
      "ROC AUC for this fold is  0.9785480076398568\n",
      "Overall score with params [188, 63, 693, 0.002718830808690577, 0.0009422336297274342, 0.00017228945369609434, 243] is -0.981908510143595\n",
      "(?, 200, 37)\n",
      "Epoch 1/2\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9801\n",
      " ROC-AUC - epoch: 1 - score: 0.979619 \n",
      "\n",
      "151592/151592 [==============================] - 51s 335us/step - loss: 0.0590 - acc: 0.9801\n",
      "Epoch 2/2\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9842\n",
      " ROC-AUC - epoch: 2 - score: 0.981688 \n",
      "\n",
      "151592/151592 [==============================] - 51s 336us/step - loss: 0.0408 - acc: 0.9842\n",
      "ROC AUC for this fold is  0.9816875864328961\n",
      "(?, 200, 37)\n",
      "Epoch 1/2\n",
      "151443/151592 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9799\n",
      " ROC-AUC - epoch: 1 - score: 0.982151 \n",
      "\n",
      "151592/151592 [==============================] - 51s 336us/step - loss: 0.0587 - acc: 0.9799\n",
      "Epoch 2/2\n",
      "151443/151592 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9842\n",
      " ROC-AUC - epoch: 2 - score: 0.983661 \n",
      "\n",
      "151592/151592 [==============================] - 51s 335us/step - loss: 0.0408 - acc: 0.9842\n",
      "ROC AUC for this fold is  0.983660603408001\n",
      "(?, 200, 37)\n",
      "Epoch 1/2\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9797\n",
      " ROC-AUC - epoch: 1 - score: 0.977208 \n",
      "\n",
      "151592/151592 [==============================] - 51s 338us/step - loss: 0.0593 - acc: 0.9797\n",
      "Epoch 2/2\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9843\n",
      " ROC-AUC - epoch: 2 - score: 0.980129 \n",
      "\n",
      "151592/151592 [==============================] - 51s 336us/step - loss: 0.0410 - acc: 0.9843\n",
      "ROC AUC for this fold is  0.9801287959042814\n",
      "(?, 200, 37)\n",
      "Epoch 1/2\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9797\n",
      " ROC-AUC - epoch: 1 - score: 0.979554 \n",
      "\n",
      "151592/151592 [==============================] - 51s 337us/step - loss: 0.0593 - acc: 0.9797\n",
      "Epoch 2/2\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9844\n",
      " ROC-AUC - epoch: 2 - score: 0.983189 \n",
      "\n",
      "151592/151592 [==============================] - 51s 335us/step - loss: 0.0406 - acc: 0.9844\n",
      "ROC AUC for this fold is  0.9831890064421351\n",
      "(?, 200, 37)\n",
      "Epoch 1/2\n",
      "151443/151592 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9800\n",
      " ROC-AUC - epoch: 1 - score: 0.970716 \n",
      "\n",
      "151592/151592 [==============================] - 51s 337us/step - loss: 0.0585 - acc: 0.9800\n",
      "Epoch 2/2\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9844\n",
      " ROC-AUC - epoch: 2 - score: 0.975606 \n",
      "\n",
      "151592/151592 [==============================] - 51s 335us/step - loss: 0.0407 - acc: 0.9844\n",
      "ROC AUC for this fold is  0.975606190503571\n",
      "Overall score with params [37, 52, 663, 0.0032741274355183713, 0.001649745367819878, 8.264328927007725e-07, 71] is -0.9797327192914483\n",
      "(?, 200, 103)\n",
      "Epoch 1/2\n",
      "151560/151592 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9756\n",
      " ROC-AUC - epoch: 1 - score: 0.976287 \n",
      "\n",
      "151592/151592 [==============================] - 57s 378us/step - loss: 0.0825 - acc: 0.9756\n",
      "Epoch 2/2\n",
      "151560/151592 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9827\n",
      " ROC-AUC - epoch: 2 - score: 0.978553 \n",
      "\n",
      "151592/151592 [==============================] - 57s 378us/step - loss: 0.0461 - acc: 0.9827\n",
      "ROC AUC for this fold is  0.9785534459059586\n",
      "(?, 200, 103)\n",
      "Epoch 1/2\n",
      "151560/151592 [============================>.] - ETA: 0s - loss: 0.0827 - acc: 0.9755\n",
      " ROC-AUC - epoch: 1 - score: 0.975004 \n",
      "\n",
      "151592/151592 [==============================] - 58s 380us/step - loss: 0.0827 - acc: 0.9755\n",
      "Epoch 2/2\n",
      "151560/151592 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9826\n",
      " ROC-AUC - epoch: 2 - score: 0.981197 \n",
      "\n",
      "151592/151592 [==============================] - 57s 379us/step - loss: 0.0466 - acc: 0.9826\n",
      "ROC AUC for this fold is  0.981196558500094\n",
      "(?, 200, 103)\n",
      "Epoch 1/2\n",
      "151560/151592 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9758\n",
      " ROC-AUC - epoch: 1 - score: 0.971721 \n",
      "\n",
      "151592/151592 [==============================] - 57s 379us/step - loss: 0.0817 - acc: 0.9758\n",
      "Epoch 2/2\n",
      "151560/151592 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9824\n",
      " ROC-AUC - epoch: 2 - score: 0.976544 \n",
      "\n",
      "151592/151592 [==============================] - 57s 378us/step - loss: 0.0467 - acc: 0.9824\n",
      "ROC AUC for this fold is  0.9765437382948529\n",
      "(?, 200, 103)\n",
      "Epoch 1/2\n",
      "151560/151592 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9752\n",
      " ROC-AUC - epoch: 1 - score: 0.967915 \n",
      "\n",
      "151592/151592 [==============================] - 58s 380us/step - loss: 0.0840 - acc: 0.9752\n",
      "Epoch 2/2\n",
      "151560/151592 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9821\n",
      " ROC-AUC - epoch: 2 - score: 0.980064 \n",
      "\n",
      "151592/151592 [==============================] - 57s 378us/step - loss: 0.0488 - acc: 0.9821\n",
      "ROC AUC for this fold is  0.9800638633500763\n",
      "(?, 200, 103)\n",
      "Epoch 1/2\n",
      "151560/151592 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9756\n",
      " ROC-AUC - epoch: 1 - score: 0.962656 \n",
      "\n",
      "151592/151592 [==============================] - 58s 380us/step - loss: 0.0822 - acc: 0.9756\n",
      "Epoch 2/2\n",
      "151560/151592 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9825\n",
      " ROC-AUC - epoch: 2 - score: 0.974217 \n",
      "\n",
      "151592/151592 [==============================] - 57s 379us/step - loss: 0.0464 - acc: 0.9825\n",
      "ROC AUC for this fold is  0.9742171289594977\n",
      "Overall score with params [103, 190, 664, 0.00046486793036106645, 0.0008391552454523785, 4.863857046189473e-07, 180] is -0.9763636697443007\n",
      "(?, 200, 131)\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151567/151592 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9800\n",
      " ROC-AUC - epoch: 1 - score: 0.982381 \n",
      "\n",
      "151592/151592 [==============================] - 60s 399us/step - loss: 0.0577 - acc: 0.9800\n",
      "Epoch 2/2\n",
      "151567/151592 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9850\n",
      " ROC-AUC - epoch: 2 - score: 0.983000 \n",
      "\n",
      "151592/151592 [==============================] - 61s 400us/step - loss: 0.0378 - acc: 0.9850\n",
      "ROC AUC for this fold is  0.9830000592787996\n",
      "(?, 200, 131)\n",
      "Epoch 1/2\n",
      "151567/151592 [============================>.] - ETA: 0s - loss: 0.1725 - acc: 0.9757\n",
      " ROC-AUC - epoch: 1 - score: 0.479192 \n",
      "\n",
      "151592/151592 [==============================] - 61s 399us/step - loss: 0.1725 - acc: 0.9757\n",
      "Epoch 2/2\n",
      "151436/151592 [============================>.] - ETA: 0s - loss: 0.5797 - acc: 0.9636\n",
      " ROC-AUC - epoch: 2 - score: 0.478979 \n",
      "\n",
      "151592/151592 [==============================] - 60s 398us/step - loss: 0.5796 - acc: 0.9636\n",
      "ROC AUC for this fold is  0.47897871742656667\n",
      "(?, 200, 131)\n",
      "Epoch 1/2\n",
      "151567/151592 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9800\n",
      " ROC-AUC - epoch: 1 - score: 0.980220 \n",
      "\n",
      "151592/151592 [==============================] - 61s 400us/step - loss: 0.0579 - acc: 0.9800\n",
      "Epoch 2/2\n",
      "151436/151592 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9854\n",
      " ROC-AUC - epoch: 2 - score: 0.981055 \n",
      "\n",
      "151592/151592 [==============================] - 61s 401us/step - loss: 0.0371 - acc: 0.9854\n",
      "ROC AUC for this fold is  0.981055035868211\n",
      "(?, 200, 131)\n",
      "Epoch 1/2\n",
      "151567/151592 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9801\n",
      " ROC-AUC - epoch: 1 - score: 0.983936 \n",
      "\n",
      "151592/151592 [==============================] - 61s 404us/step - loss: 0.0575 - acc: 0.9802\n",
      "Epoch 2/2\n",
      "151567/151592 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9853\n",
      " ROC-AUC - epoch: 2 - score: 0.984244 \n",
      "\n",
      "151592/151592 [==============================] - 61s 403us/step - loss: 0.0370 - acc: 0.9853\n",
      "ROC AUC for this fold is  0.9842439726685116\n",
      "(?, 200, 131)\n",
      "Epoch 1/2\n",
      "151567/151592 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9795\n",
      " ROC-AUC - epoch: 1 - score: 0.972591 \n",
      "\n",
      "151592/151592 [==============================] - 61s 400us/step - loss: 0.0584 - acc: 0.9795\n",
      "Epoch 2/2\n",
      "151567/151592 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9851\n",
      " ROC-AUC - epoch: 2 - score: 0.973719 \n",
      "\n",
      "151592/151592 [==============================] - 61s 399us/step - loss: 0.0381 - acc: 0.9851\n",
      "ROC AUC for this fold is  0.9737194283554632\n",
      "Overall score with params [131, 224, 819, 0.004228417918653105, 2.1035428134349117e-05, 0.00022409712855921124, 131] is -0.8089338526899862\n",
      "(?, 200, 232)\n",
      "Epoch 1/2\n",
      "151425/151592 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9770\n",
      " ROC-AUC - epoch: 1 - score: 0.977211 \n",
      "\n",
      "151592/151592 [==============================] - 69s 457us/step - loss: 0.0725 - acc: 0.9770\n",
      "Epoch 2/2\n",
      "151425/151592 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9841\n",
      " ROC-AUC - epoch: 2 - score: 0.978639 \n",
      "\n",
      "151592/151592 [==============================] - 70s 459us/step - loss: 0.0417 - acc: 0.9841\n",
      "ROC AUC for this fold is  0.9786387471844195\n",
      "(?, 200, 232)\n",
      "Epoch 1/2\n",
      "151425/151592 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9769\n",
      " ROC-AUC - epoch: 1 - score: 0.978410 \n",
      "\n",
      "151592/151592 [==============================] - 70s 460us/step - loss: 0.0737 - acc: 0.9770\n",
      "Epoch 2/2\n",
      "151425/151592 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9839\n",
      " ROC-AUC - epoch: 2 - score: 0.980503 \n",
      "\n",
      "151592/151592 [==============================] - 69s 458us/step - loss: 0.0422 - acc: 0.9839\n",
      "ROC AUC for this fold is  0.9805028987671683\n",
      "(?, 200, 232)\n",
      "Epoch 1/2\n",
      "151425/151592 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9771\n",
      " ROC-AUC - epoch: 1 - score: 0.978405 \n",
      "\n",
      "151592/151592 [==============================] - 70s 460us/step - loss: 0.0719 - acc: 0.9771\n",
      "Epoch 2/2\n",
      "151425/151592 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9841\n",
      " ROC-AUC - epoch: 2 - score: 0.978896 \n",
      "\n",
      "151592/151592 [==============================] - 69s 458us/step - loss: 0.0412 - acc: 0.9841\n",
      "ROC AUC for this fold is  0.9788959372266136\n",
      "(?, 200, 232)\n",
      "Epoch 1/2\n",
      "151425/151592 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9774\n",
      " ROC-AUC - epoch: 1 - score: 0.979097 \n",
      "\n",
      "151592/151592 [==============================] - 69s 453us/step - loss: 0.0730 - acc: 0.9774\n",
      "Epoch 2/2\n",
      "151425/151592 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9838\n",
      " ROC-AUC - epoch: 2 - score: 0.981427 \n",
      "\n",
      "151592/151592 [==============================] - 69s 454us/step - loss: 0.0424 - acc: 0.9838\n",
      "ROC AUC for this fold is  0.9814265132458532\n",
      "(?, 200, 232)\n",
      "Epoch 1/2\n",
      "151425/151592 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9776\n",
      " ROC-AUC - epoch: 1 - score: 0.966967 \n",
      "\n",
      "151592/151592 [==============================] - 70s 459us/step - loss: 0.0711 - acc: 0.9776\n",
      "Epoch 2/2\n",
      "151425/151592 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9842\n",
      " ROC-AUC - epoch: 2 - score: 0.973075 \n",
      "\n",
      "151592/151592 [==============================] - 70s 460us/step - loss: 0.0411 - acc: 0.9842\n",
      "ROC AUC for this fold is  0.973075106237849\n",
      "Overall score with params [232, 193, 819, 0.0007660826482436302, 0.00036485656261804145, 4.010174523739503e-05, 225] is -0.9779524572618891\n",
      "(?, 200, 25)\n",
      "Epoch 1/2\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9772\n",
      " ROC-AUC - epoch: 1 - score: 0.975908 \n",
      "\n",
      "151592/151592 [==============================] - 45s 294us/step - loss: 0.0714 - acc: 0.9772\n",
      "Epoch 2/2\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9836\n",
      " ROC-AUC - epoch: 2 - score: 0.976649 \n",
      "\n",
      "151592/151592 [==============================] - 44s 293us/step - loss: 0.0438 - acc: 0.9836\n",
      "ROC AUC for this fold is  0.9766493775364063\n",
      "(?, 200, 25)\n",
      "Epoch 1/2\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9776\n",
      " ROC-AUC - epoch: 1 - score: 0.979397 \n",
      "\n",
      "151592/151592 [==============================] - 45s 295us/step - loss: 0.0708 - acc: 0.9776\n",
      "Epoch 2/2\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9836\n",
      " ROC-AUC - epoch: 2 - score: 0.979504 \n",
      "\n",
      "151592/151592 [==============================] - 44s 293us/step - loss: 0.0436 - acc: 0.9836\n",
      "ROC AUC for this fold is  0.979503631593044\n",
      "(?, 200, 25)\n",
      "Epoch 1/2\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9768\n",
      " ROC-AUC - epoch: 1 - score: 0.976003 \n",
      "\n",
      "151592/151592 [==============================] - 45s 294us/step - loss: 0.0720 - acc: 0.9768\n",
      "Epoch 2/2\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9835\n",
      " ROC-AUC - epoch: 2 - score: 0.976447 \n",
      "\n",
      "151592/151592 [==============================] - 44s 293us/step - loss: 0.0436 - acc: 0.9835\n",
      "ROC AUC for this fold is  0.9764472327389656\n",
      "(?, 200, 25)\n",
      "Epoch 1/2\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9777\n",
      " ROC-AUC - epoch: 1 - score: 0.979131 \n",
      "\n",
      "151592/151592 [==============================] - 45s 294us/step - loss: 0.0698 - acc: 0.9777\n",
      "Epoch 2/2\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9835\n",
      " ROC-AUC - epoch: 2 - score: 0.980186 \n",
      "\n",
      "151592/151592 [==============================] - 44s 293us/step - loss: 0.0432 - acc: 0.9835\n",
      "ROC AUC for this fold is  0.9801854316928432\n",
      "(?, 200, 25)\n",
      "Epoch 1/2\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0787 - acc: 0.9749\n",
      " ROC-AUC - epoch: 1 - score: 0.969714 \n",
      "\n",
      "151592/151592 [==============================] - 44s 293us/step - loss: 0.0787 - acc: 0.9749\n",
      "Epoch 2/2\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9831\n",
      " ROC-AUC - epoch: 2 - score: 0.971242 \n",
      "\n",
      "151592/151592 [==============================] - 44s 293us/step - loss: 0.0447 - acc: 0.9831\n",
      "ROC AUC for this fold is  0.9712422297781508\n",
      "Overall score with params [25, 201, 703, 0.001944756315639371, 1.7526555841926e-05, 2.333469328026268e-06, 235] is -0.9767305384316131\n",
      "(?, 200, 130)\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151550/151592 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9795\n",
      " ROC-AUC - epoch: 1 - score: 0.977509 \n",
      "\n",
      "151592/151592 [==============================] - 127s 841us/step - loss: 0.0613 - acc: 0.9795\n",
      "Epoch 2/2\n",
      "151550/151592 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9844\n",
      " ROC-AUC - epoch: 2 - score: 0.978575 \n",
      "\n",
      "151592/151592 [==============================] - 127s 838us/step - loss: 0.0406 - acc: 0.9844\n",
      "ROC AUC for this fold is  0.9785749695939608\n",
      "(?, 200, 130)\n",
      "Epoch 1/2\n",
      "151550/151592 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9796\n",
      " ROC-AUC - epoch: 1 - score: 0.979589 \n",
      "\n",
      "151592/151592 [==============================] - 127s 840us/step - loss: 0.0607 - acc: 0.9796\n",
      "Epoch 2/2\n",
      "151550/151592 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9842\n",
      " ROC-AUC - epoch: 2 - score: 0.980123 \n",
      "\n",
      "151592/151592 [==============================] - 127s 836us/step - loss: 0.0408 - acc: 0.9842\n",
      "ROC AUC for this fold is  0.9801229709965509\n",
      "(?, 200, 130)\n",
      "Epoch 1/2\n",
      "151550/151592 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9797\n",
      " ROC-AUC - epoch: 1 - score: 0.977616 \n",
      "\n",
      "151592/151592 [==============================] - 127s 838us/step - loss: 0.0608 - acc: 0.9797\n",
      "Epoch 2/2\n",
      "151550/151592 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9842\n",
      " ROC-AUC - epoch: 2 - score: 0.978647 \n",
      "\n",
      "151592/151592 [==============================] - 127s 837us/step - loss: 0.0408 - acc: 0.9842\n",
      "ROC AUC for this fold is  0.9786470731369955\n",
      "(?, 200, 130)\n",
      "Epoch 1/2\n",
      "151550/151592 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9799\n",
      " ROC-AUC - epoch: 1 - score: 0.979844 \n",
      "\n",
      "151592/151592 [==============================] - 127s 838us/step - loss: 0.0605 - acc: 0.9799\n",
      "Epoch 2/2\n",
      "151550/151592 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9844\n",
      " ROC-AUC - epoch: 2 - score: 0.980418 \n",
      "\n",
      "151592/151592 [==============================] - 127s 837us/step - loss: 0.0402 - acc: 0.9844\n",
      "ROC AUC for this fold is  0.9804184726612338\n",
      "(?, 200, 130)\n",
      "Epoch 1/2\n",
      "151550/151592 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9797\n",
      " ROC-AUC - epoch: 1 - score: 0.971314 \n",
      "\n",
      "151592/151592 [==============================] - 127s 837us/step - loss: 0.0607 - acc: 0.9797\n",
      "Epoch 2/2\n",
      "151550/151592 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9845\n",
      " ROC-AUC - epoch: 2 - score: 0.971221 \n",
      "\n",
      "151592/151592 [==============================] - 127s 836us/step - loss: 0.0403 - acc: 0.9845\n",
      "ROC AUC for this fold is  0.971220699938803\n",
      "Overall score with params [130, 199, 92, 0.0009241707704121684, 1.1046784818354062e-05, 1.225116771800311e-05, 70] is -0.977704066116015\n",
      "(?, 200, 248)\n",
      "Epoch 1/2\n",
      "151569/151592 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9810\n",
      " ROC-AUC - epoch: 1 - score: 0.982994 \n",
      "\n",
      "151592/151592 [==============================] - 199s 1ms/step - loss: 0.0541 - acc: 0.9810\n",
      "Epoch 2/2\n",
      "120087/151592 [======================>.......] - ETA: 41s - loss: 0.0348 - acc: 0.9862"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7f5c9ce2e51f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         ]\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mres_gp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbrt_minimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gru\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/skopt/optimizer/gbrt.py\u001b[0m in \u001b[0;36mgbrt_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, xi, kappa, n_jobs)\u001b[0m\n\u001b[1;32m    151\u001b[0m                          \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                          \u001b[0mkappa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkappa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macq_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                          callback=callback, acq_optimizer=\"sampling\")\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-704d933bb7dd>\u001b[0m in \u001b[0;36mtrain_gru\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         model.fit(X_train, y_train, batch_size=batch_size, epochs=2, validation_split=0.0, verbose=1, \n\u001b[0;32m---> 56\u001b[0;31m                   callbacks=[RocAuc, LRDecay])\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ROC AUC for this fold is \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "space = [Integer(16, 256), #name='embed_size'),\n",
    "         Integer(16, 256),# name='gru_dim'),\n",
    "         Integer(64, 1024),# name='dense_dim'),\n",
    "         Real(0.0001, 0.005, \"log-uniform\"), #name='lr1'),\n",
    "         Real(1e-5, 0.002, \"log-uniform\"), #name='lr2'),\n",
    "         Real(1e-8, 0.001, \"log-uniform\"), #name='decay'),\n",
    "         Integer(32, 256),# name=batch'),\n",
    "        ]\n",
    "\n",
    "res_gp = gbrt_minimize(train_gru, space, n_calls=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_trues' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-3f5efbe5120f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_trues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_trues' is not defined"
     ]
    }
   ],
   "source": [
    "y_trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9861737784746518"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "159456/159571 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9818\n",
      " ROC-AUC - epoch: 1 - score: 0.992135 \n",
      "\n",
      "159571/159571 [==============================] - 84s 528us/step - loss: 0.0498 - acc: 0.9818\n",
      "Epoch 2/3\n",
      "159488/159571 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9850\n",
      " ROC-AUC - epoch: 2 - score: 0.995249 \n",
      "\n",
      "159571/159571 [==============================] - 83s 523us/step - loss: 0.0384 - acc: 0.9850\n",
      "Epoch 3/3\n",
      "159488/159571 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9880\n",
      " ROC-AUC - epoch: 3 - score: 0.995429 \n",
      "\n",
      "159571/159571 [==============================] - 84s 525us/step - loss: 0.0307 - acc: 0.9880\n",
      "153164/153164 [==============================] - 2s 15us/step\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.fit(X_t, y, batch_size=32, epochs=3, validation_split=0.0, verbose=1, \n",
    "              callbacks=[RocAuc, LRDecay])\n",
    "y_test_preds = model.predict([X_te], batch_size=1024, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for class toxic is 0.9791088111561013\n",
      "Score for class severe_toxic is 0.9896361881404786\n",
      "Score for class obscene is 0.989792727484462\n",
      "Score for class threat is 0.9834375512104746\n",
      "Score for class insult is 0.9851961777705942\n",
      "Score for class identity_hate is 0.9837426177272286\n",
      "Over auc score 0.9851523455815565\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "y_trues = train[label_cols].values\n",
    "y_preds2 = np.zeros((X_t.shape[0], len(label_cols)))\n",
    "y_test_preds2 = np.zeros((X_te.shape[0], len(label_cols)))\n",
    "for i, col in enumerate(label_cols):\n",
    "    y = y_trues[:, i]\n",
    "    #model = RandomForestClassifier(n_estimators=100, max_depth=6, min_samples_leaf=50, class_weight='balanced', n_jobs=-1)\n",
    "    model = lgb.LGBMClassifier(n_estimators=100, num_leaves=5, learning_rate=0.03, \n",
    "                               subsample=0.9, colsample_bytree=0.9)\n",
    "    y_preds2[:, i] = cross_val_predict(model, y_preds, y, cv=cvlist, n_jobs=1, method='predict_proba')[:,1]\n",
    "    y_test_preds2[:, i] = model.fit(y_preds, y).predict_proba(y_test_preds)[:,1]\n",
    "    print(\"Score for class {} is {}\".format(col, roc_auc_score(y, y_preds2[:, i])))\n",
    "print(\"Over auc score\", roc_auc_score(y_trues, y_preds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[label_cols] = y_test_preds\n",
    "sample_submission.to_csv('nn_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[label_cols] = y_test_preds2\n",
    "sample_submission.to_csv('nn_lgbmeta_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
